name: Deploy EKS Cluster & Nodes

on:
  workflow_dispatch:
    inputs:
      AWS_REGION:
        description: 'AWS Region'
        required: true
        default: 'ap-southeast-2'
      TF_VERSION:
        description: 'Terraform Version'
        required: true
        default: '1.12.0'
      HELM_VERSION:
        description: 'Helm Version'
        required: true
        default: 'v3.14.4'
      DESTROY:
        description: 'Set to true to destroy the infrastructure'
        required: false
        default: 'false'

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: prod
    env:
      AWS_REGION: ${{ inputs.AWS_REGION }}
      TF_VERSION: ${{ inputs.TF_VERSION }}
      HELM_VERSION: ${{ inputs.HELM_VERSION }}
      CLUSTER_NAME: ${{ secrets.CLUSTER_NAME }}
      DOMAIN_NAME: ${{ secrets.DOMAIN_NAME }}
      EBS_CSI_IAM_ROLE_ARN: ${{ vars.EBS_CSI_IAM_ROLE_ARN }}
      EKS_CLUSTER_IAM_ROLE_ARN: ${{ vars.EKS_CLUSTER_IAM_ROLE_ARN }}
      EKS_NODEGROUP_IAM_ROLE_ARN: ${{ vars.EKS_NODEGROUP_IAM_ROLE_ARN }}
      LB_CONTROLLER_IAM_ROLE_ARN: ${{ vars.LB_CONTROLLER_IAM_ROLE_ARN }}
      VPC_ID: ${{ vars.VPC_ID }}
      # SUBNET_IDA: ${{ vars.SUBNET_IDA }}
      # SUBNET_IDB: ${{ vars.SUBNET_IDB }}
      ACM_CERTIFICATE_ARN: ${{ vars.ACM_CERTIFICATE_ARN }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ inputs.TF_VERSION }}

      - name: Install AWS CLI
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install --update

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ap-southeast-2
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Terraform Init
        run: terraform init -upgrade
        working-directory: terraform/eks-cluster

      - name: Terraform Validate
        run: terraform validate
        working-directory: terraform/eks-cluster
      - name: Terraform Plan
        run: terraform plan -input=false -out=tfplan
        working-directory: terraform/eks-cluster
        env:
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_VAR_cluster_name: ${{ secrets.CLUSTER_NAME }}
          TF_VAR_domain_name: ${{ secrets.DOMAIN_NAME }}
          TF_VAR_vpc_id: ${{ env.VPC_ID }}
          TF_VAR_acm_certificate_arn: ${{ env.ACM_CERTIFICATE_ARN }}
          TF_VAR_ebs_csi_iam_role_arn: ${{ env.EBS_CSI_IAM_ROLE_ARN }}
          TF_VAR_eks_cluster_role_arn: ${{ env.EKS_CLUSTER_IAM_ROLE_ARN }}
          TF_VAR_nodegroup_role_arn: ${{ env.EKS_NODEGROUP_IAM_ROLE_ARN }}
          TF_VAR_lb_controller_iam_role_arn: ${{ env.LB_CONTROLLER_IAM_ROLE_ARN }}
          # TF_VAR_subnet_ida: ${{ env.SUBNET_IDA }}
          # TF_VAR_subnet_idb: ${{ env.SUBNET_IDB }}
      - name: Terraform Plan or Destroy
        run: |
          if [[ "${{ github.event.inputs.DESTROY }}" == "true" ]]; then
            echo "Destroy mode active"
            terraform destroy -auto-approve
          else
            echo "Plan + Apply mode active"
            terraform plan \
              -var="aws_region=${{ env.AWS_REGION }}" \
              -var="cluster_name=${{ env.CLUSTER_NAME }}" \
              -var="vpc_id=${{ env.VPC_ID }}" \
              -out=tfplan
            terraform apply -auto-approve tfplan
          fi
        working-directory: terraform/eks-cluster
        env:
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_VAR_cluster_name: ${{ env.CLUSTER_NAME }}
          TF_VAR_domain_name: ${{ env.DOMAIN_NAME }}
          TF_VAR_vpc_id: ${{ env.VPC_ID }}
          TF_VAR_acm_certificate_arn: ${{ env.ACM_CERTIFICATE_ARN }}
          TF_VAR_ebs_csi_iam_role_arn: ${{ env.EBS_CSI_IAM_ROLE_ARN }}
          TF_VAR_eks_cluster_role_arn: ${{ env.EKS_CLUSTER_IAM_ROLE_ARN }}
          TF_VAR_nodegroup_role_arn: ${{ env.EKS_NODEGROUP_IAM_ROLE_ARN }}
          TF_VAR_lb_controller_iam_role_arn: ${{ env.LB_CONTROLLER_IAM_ROLE_ARN }}
          # TF_VAR_subnet_ida: ${{ env.SUBNET_IDA }}
          # TF_VAR_subnet_idb: ${{ env.SUBNET_IDB }}


      - name: Install kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: ${{ env.HELM_VERSION }}

      - name: Configure kubeconfig
        run: |
          aws eks --region ${{ env.AWS_REGION }} update-kubeconfig \
            --name ${{ env.CLUSTER_NAME }} \
            --alias ${{ env.CLUSTER_NAME }}

      - name: Deploy Helm Chart
        run: |
          helm dependency update ./helm/nginx
          helm upgrade --install nginx ./helm/nginx \
            --namespace default \
            --create-namespace \
            --set ingress.annotations.alb\.ingress\.kubernetes\.io/certificate-arn=$(terraform output -raw acm_certificate_arn) \
            --set ingress.hosts[0].host=${{ env.DOMAIN_NAME }} \
            --atomic \
            --timeout 10m
        working-directory: terraform/eks-cluster